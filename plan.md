# LLM学習用アプリケーション 開発計画

## プロジェクト概要
LLMの基礎知識を学習しながら、実際に自分のLLMモデルを作成できるインタラクティブな学習アプリケーション

## コンセプト
- 学びながら自分のLLMを作成できる
- LLMの基礎知識の学習フェーズ
- 実際にLLMを作成する実践フェーズ
- オープンソースモデル(Hugging Face)を使った転移学習

## 技術スタック
- **バックエンド**: Python 3.9+
- **LLMライブラリ**: Hugging Face Transformers
- **フロントエンド**: Streamlit (シンプルなUI)
- **モデル**: GPT-2 (小規模で学習用に最適)
- **テスト**: pytest

## プロジェクト構造
```
llm-learning-app/
├── src/
│   ├── learning/          # 学習コンテンツモジュール
│   ├── training/          # モデルトレーニングモジュール
│   ├── utils/             # ユーティリティ関数
│   └── app.py             # Streamlitアプリケーション
├── tests/                 # テストコード
├── data/                  # サンプルデータ
├── models/                # 保存されたモデル
├── requirements.txt       # 依存パッケージ
├── README.md              # プロジェクトドキュメント
└── plan.md                # この開発計画書
```

## 開発フェーズ

### Phase 1: プロジェクトセットアップ ✓
- [x] プロジェクト構造の作成
- [x] 開発計画の作成
- [x] 依存パッケージのリスト作成
- [x] 基本的なディレクトリ構造の構築

### Phase 2: 学習コンテンツモジュール ✓
- [x] LLM基礎知識のコンテンツ作成
  - [x] LLMとは何か
  - [x] Transformerアーキテクチャ
  - [x] トークナイゼーション
  - [x] 転移学習
  - [x] ファインチューニング実践
- [x] インタラクティブなクイズ機能
- [x] テスト: 学習コンテンツの単体テスト

### Phase 3: モデルトレーニングモジュール ✓
- [x] モデルローダーの実装
- [x] データセット準備機能
- [x] ファインチューニング機能
- [x] モデル保存・読み込み機能
- [x] テスト: トレーニング機能の単体テスト

### Phase 4: UIの実装 ✓
- [x] Streamlitアプリケーションの基本構造
- [x] 学習フェーズのUI
- [x] トレーニングフェーズのUI
- [x] モデルテストのUI
- [x] ユーティリティ関数の実装とテスト

### Phase 5: ドキュメント作成 ✓
- [x] README.mdの完成
- [x] 使い方ガイド
- [x] プロジェクト構造の説明

## 実施内容ログ

### 2025-12-13
#### 完了したこと
1. プロジェクトの調査完了
   - 既存のLLM学習サービスを調査（テックアカデミー、Udemy等）
   - Hugging Face Transformersの使用方法を調査
   - 利用可能なオープンソースモデルを確認（GPT-2、LLaMA、Gemma等）

2. プロジェクト構造の設計と実装
   - ミニマムな機能に絞った設計
   - TDD（テスト駆動開発）を意識した構造

3. 依存パッケージの定義
   - requirements.txtの作成
   - Hugging Face Transformers、Streamlit、PyTorchなど

4. 学習コンテンツモジュールの実装
   - content.py: 5つのトピック（LLM基礎、Transformer、トークナイゼーション、転移学習、ファインチューニング）
   - quiz.py: 各トピック3問ずつのクイズ機能
   - test_learning.py: 完全なテストカバレッジ

5. トレーニングモジュールの実装
   - model_loader.py: モデルとトークナイザーのロード、テキスト生成
   - data_processor.py: データの前処理、トークナイゼーション
   - trainer.py: シンプルなファインチューニング機能
   - test_training.py: データ処理のテスト

6. ユーティリティモジュールの実装
   - helpers.py: 共通の便利関数
   - test_utils.py: ユーティリティのテスト

7. UIの実装
   - app.py: Streamlitベースのインタラクティブなアプリケーション
   - 学習モード: トピック表示、クイズ、進捗管理
   - トレーニングモード: モデルロード、データ準備、トレーニング実行、テキスト生成

8. ドキュメント作成
   - README.md: セットアップ、使い方、プロジェクト構造
   - plan.md: 開発計画と進捗記録

#### 実装した主要機能

**学習モード:**
- 5つの学習トピック（詳細な説明付き）
- 各トピック3問のクイズ（全15問）
- 進捗トラッキング
- 即座のフィードバックと解説

**トレーニングモード:**
- GPT-2（英語・日本語）のロード
- サンプルデータまたはカスタムテキストでのトレーニング
- ハイパーパラメータの調整（エポック、学習率、バッチサイズ等）
- トレーニング進捗の可視化
- テキスト生成のデモ
- モデルの保存機能

**テスト:**
- pytest使用
- 学習モジュール: 12テスト
- トレーニングモジュール: 8テスト  
- ユーティリティ: 15テスト
- 合計35以上のテストケース

#### 技術的な決定

1. **モデル選択**: GPT-2
   - 小規模で学習が速い
   - 教育目的に最適
   - CPU環境でも動作可能

2. **UI Framework**: Streamlit
   - シンプルで直感的
   - Pythonのみで完結
   - インタラクティブな要素が豊富

3. **テスト戦略**: TDD
   - 各モジュールに対応するテストファイル
   - モックを使って実際のモデルロードを避ける
   - エッジケースのカバレッジ

4. **データ処理**: ミニマルな実装
   - シンプルなバッチ処理
   - メモリ効率を考慮
   - 小規模データセットに最適化

#### 次のステップ（今後の拡張案）
1. より高度なファインチューニング手法（LoRA、QLoRA）
2. 複数モデルのサポート
3. より詳細な評価メトリクス
4. データセットのバリデーション機能
5. モデル比較機能
6. エクスポート機能の強化

## 設計上の決定事項

### モデル選択
- **GPT-2**: 小規模で学習が速く、教育目的に最適
- 日本語対応が必要な場合は、`rinna/japanese-gpt2-medium`を使用

### ミニマム機能
1. **学習フェーズ**
   - 5つの基礎トピック
   - 各トピックに簡単なクイズ

2. **実践フェーズ**
   - サンプルテキストデータでのファインチューニング
   - シンプルなテキスト生成デモ

### TDD方針
- 各モジュールに対応するテストファイルを作成
- 新機能追加前に必ずテストを作成
- pytest-covでカバレッジを80%以上維持
